name: Performance

on:
  push:
    branches: [ "master" ]
  pull_request:
    branches: [ "master" ]
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: write
  pull-requests: write

jobs:
  benchmark:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Install Rust stable
        uses: dtolnay/rust-toolchain@v1
        with:
          toolchain: stable

      - name: Build release
        run: |
          time cargo build --release --verbose 2>&1 | tee build.log

      - name: Collect binary size
        run: |
          ls -lh target/release/rtop
          size target/release/rtop
          
          # Create metrics file
          echo "# Binary Size Report" > metrics.md
          echo "" >> metrics.md
          echo "\`\`\`" >> metrics.md
          ls -lh target/release/rtop >> metrics.md
          echo "" >> metrics.md
          size target/release/rtop >> metrics.md
          echo "\`\`\`" >> metrics.md

      - name: Strip binary and measure
        run: |
          strip target/release/rtop
          echo "" >> metrics.md
          echo "## After stripping:" >> metrics.md
          echo "\`\`\`" >> metrics.md
          ls -lh target/release/rtop >> metrics.md
          echo "\`\`\`" >> metrics.md

      - name: Measure startup time
        run: |
          echo "" >> metrics.md
          echo "## Startup Performance:" >> metrics.md
          echo "\`\`\`" >> metrics.md
          for i in {1..5}; do
            /usr/bin/time -v timeout 1s target/release/rtop 2>&1 | grep "Elapsed" || true
          done >> metrics.md
          echo "\`\`\`" >> metrics.md

      - name: Measure memory usage
        run: |
          echo "" >> metrics.md
          echo "## Memory Usage:" >> metrics.md
          echo "\`\`\`" >> metrics.md
          timeout 5s /usr/bin/time -v target/release/rtop 2>&1 | grep -E "Maximum resident|Average resident" || true
          echo "\`\`\`" >> metrics.md

      - name: Extract metrics to JSON
        run: |
          binary_size=$(stat -c%s target/release/rtop)
          build_time=$(grep "Finished" build.log | grep -oP '\d+\.\d+s' | head -1 | sed 's/s//')
          
          cat > metrics.json << EOF
          [
            {"name": "Binary Size (bytes)", "unit": "bytes", "value": $binary_size},
            {"name": "Build Time", "unit": "seconds", "value": ${build_time:-0}}
          ]
          EOF
          cat metrics.json

      - name: Display metrics
        run: cat metrics.md

      - name: Prepare benchmark files
        run: |
          mkdir -p benchmark-output
          cp metrics.md metrics.json benchmark-output/
          
          # Create index.html for viewing
          cat > benchmark-output/index.html << 'EOF'
          <!DOCTYPE html>
          <html>
          <head>
            <title>rtop Performance Benchmarks</title>
            <meta charset="utf-8">
            <style>
              body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; margin: 40px auto; max-width: 800px; line-height: 1.6; padding: 0 20px; }
              pre { background: #f5f5f5; padding: 15px; border-radius: 5px; overflow-x: auto; }
              h1 { color: #0366d6; }
              .metric { background: #f6f8fa; padding: 10px; margin: 10px 0; border-left: 3px solid #0366d6; }
            </style>
          </head>
          <body>
            <h1>üìä rtop Performance Benchmarks</h1>
            <p><a href="https://github.com/npequeux/rtop">‚Üê Back to Repository</a></p>
            <div id="content"></div>
            <script>
              fetch('metrics.md')
                .then(r => r.text())
                .then(md => {
                  document.getElementById('content').innerHTML = '<pre>' + md + '</pre>';
                });
            </script>
          </body>
          </html>
          EOF

      - name: Upload metrics
        uses: actions/upload-artifact@v4
        with:
          name: performance-metrics
          path: benchmark-output/

      - name: Deploy benchmark to Pages
        if: github.ref == 'refs/heads/master' && github.event_name == 'push'
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: benchmark-output
          destination_dir: dev/bench
          keep_files: false
          user_name: 'github-actions[bot]'
          user_email: 'github-actions[bot]@users.noreply.github.com'
          commit_message: 'Update benchmark results'

      - name: Comment PR with metrics
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const metrics = fs.readFileSync('metrics.md', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## üìä Performance Metrics\n\n${metrics}\n\n[View historical trends](https://npequeux.github.io/rtop/dev/bench/)`
            });
